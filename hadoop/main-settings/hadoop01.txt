一、引出hadoop
1、hadoop的高薪现状
给出几个招聘截图----> 高薪，职位所需求的技能
----> 引出好奇，hadoop是什么，为什么会这么高薪？引出大数据，大数据时代，大数据与云计算

2、大数据时代的介绍
大数据的故事，google根据海量数据所作出的一次流行病传播趋势预测，及时性和准确性都远超医疗体系根据传统方法所作出的预警，渲染大数据技术将给这个时代带来的巨大变革 ----> 大数据的4V特征  ----> 大数据技术带来的更多成功案例，及基于大数据技术的机器学习带来的无限憧憬

3、hadoop的由来和发展历程 
----> google所面临的困境 ----> 需求催生的技术革新 ----> 论文公布  ---->  dougcutting 山寨（捎带介绍一下道哥及其成就） ----> lucene nutch hadoop等项目的发起人 ----> yahoo ----> apache基金会管理维护
介绍apache基金会及其重要项目
介绍apache基金会旗下的hadoop生态体系中各种开源项目，入hive  hbase  flume  spark  storm  sqoop   oozie  ......（此处只是略带浏览一下，后面详细讲解hadoop生态系统）


4、hadoop解决了什么问题
此处尽量通俗浅显地描述（先通过实际场景举例来引导：实际场景，海量日志如何处理，海量网页数据如何处理）
hdfs  解决了海量数据的分布式存储，高可靠，易扩展，高吞吐量
mapreduce   解决了海量数据的分析处理，通用性强，易开发，健壮性


5、hadoop的发展现况
大数据领域的标准开源解决方案，各大主流厂商都围绕hadoop进行周边开发和服务提供，去IOE化
重点以淘宝为例： 集群用途，个数，规模，云梯的架构
顺带介绍中国移动所使用的hadoop集群及其用途
（笑料：各大厂商在使用hadoop，itcast也在使用hadoop）

6、hadoop生态系统
分层次讲解----> 最底层平台 hdfs   yarn  mapreduce  spark
---- > 应用层   hbase  hive pig  sparkSQL  nutch 
----> 工具类   zookeeper  flume 


二、hadoop介绍
1、如何学习hadoop
学什么？分轻重缓急，首先是整体技术架构，然后是应用场景，然后是开发规范，有余力可以深入原理--如源码）
怎样学？注意比较跟学习J2EE的差别
难不难？给以信心，强调要多动手，因为hadoop领域技术点多，不像j2ee那么单纯，在动手的过程中会遇到各种各样的问题，这样一能加深理解，二能提高学习和思考分析的能力，三能积累问题解决经验

2、hadoop的设计思想
单机性能纵向扩展的瓶颈，传统分布式存储入NFS所面临的单节点故障，磁盘冗余阵列所带来的成本问题
----> 需要通过集群协作来解决：水平扩展，集群化处理 ，低成本，可扩展，高可靠 
----> 集群协作随之而来的系统复杂度，急需一个通用的平台封装底层复杂度，降低使用开发难度

hdfs设计思想介绍 
	----主从结构， 主节点namenode，从节点datanode ，简单介绍其角色责任，节点数量
用仓库管理系统的比喻方式来介绍一遍hdfs的设计思想：
	---->管理员，仓库的角色
	---->可靠性的考虑
	---->吞吐量的考虑
	---->存储和读取的流程


mapreduce设计思想介绍 
	----主从结构，主节点jobtracker，从节点 tasktracker，整个框架如何将任务并发化，如何实现容错
	---->用一个海量求和的案例来说明运算的并发化思想：
                  a、用一个线程一次性全量求和
		  b、将整个求和任务分成两个步骤，第一个步骤局部求和，这样可以并发进行；第二个步骤必须全局处理，用一个线程来执行，但是它的输入数据集已经很小，不会成为瓶颈

	---->并发思想的编程模型实现了，但是并发协作的机制产生了大量公共管理问题，引出mapreduce的资源管理，任务调度，错误重试，并从这里可以引出hadoop2.0的yarn的思想及与hadoop1.0的对比



三、hadoop的部署----（细节在《hadoop2.4.1伪分布式搭建.txt》中）
1、linux系统的安装、配置（这部分都是实际操作演示）
根据以往经验，学员对于虚拟机软件特别是虚拟网络环境很困惑，这里需要详细讲一下虚拟机的思想
可先讲实际环境，要物理机，要交换机，要网络配置
那么，在虚拟环境下，同样需要具备这些要素，缺一不可，只是机器，交换机需要用虚拟的方式产生的而已；然后详细讲一下交换机和网关的概念，引出nat和bridge桥接方式的思想和差别 

准备工作：vmware虚拟机软件，centos6.5的安装，虚拟机软件的vmnet配置，nat方式或者桥接方式
a、网络配置----> 主机名，ip地址，域名映射 

先用ifconfig查看目前的活跃网卡，然后修改网卡的ip地址配置
setup配置ip地址（简易图形界面）或者
vi /etc/sysconfig/networking/devices/ifcfg-eth0 配置文件来修改ip地址
IPADDR=""
NETMASK=""
GATEWAY=""

主机名和域名映射的配置：
vi /etc/sysconfig/network  本机的主机名
vi /etc/hosts  集群中的主机域名映射表


----> 检验配置是否生效
ping hostname观察网络配置是否生效


b、系统配置 
----> sudoers加入普通用户，以便于利用sudo指令、时间配置，启动级别配置，防火墙配置
service iptables stop 关闭防火墙服务
chkconfig iptables off关闭防火墙自启动
service iptables status检查防火墙关闭情况
chkconfig iptables --list 查看防火墙自启动情况



2、JDK的安装(细节在《hadoop2.4.1伪分布式搭建.txt》中)
JDK安装包获取----> 安装包的上传 ----> 安装路径规划，安装包解压 ----> 环境变量的配置

secureCRT 
vsftp
tar  -zxvf
vi  /etc/profile
export JAVA_HOME=/usr/java
export PATH = $PATH:$JAVA_HOME/bin
source /etc/profile 生效

3、安装hadoop(细节在《hadoop2.4.1伪分布式搭建.txt》中)
hadoop版本的选择 hadoop-1.2.1  hadoop-2.2.0   hadoop-2.4.1
----> 下载安装包 http://archive.apache.org/dist 
----> 上传安装包到虚拟机
安装路径规划 ----> 解压 ----> 目录结构简介

伪分布式安装配置文件
vi hadoop-env.sh
export JAVA_HOME=/usr/java/jdk1.7.0_65

core-site.xml
<property>
<name>fs.defaultFS</name>
<value>hdfs://itcast:9000</value>
</property>
<property>
<name>hadoop.tmp.dir</name>
<value>/home/hadoop/hadoop-2.4.1/tmp</value>
</property>


hdfs-site.xml
<property>
<name>dfs.replication</name>
<value>1</value>
</property>


mapred-site.xml
<property>
<name>mapreduce.framwork.name</name>
<value>yarn</value>
</property>

yarn-site.xml
<property>
<name>yarn.resourcemanager.hostname</name>
<value>itcast</value>
</property>

<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>

配置/etc/profile
export HADOOP_HOME = 
export PATH

4、启动hadoop
格式化 hdfs namenode -format
start-all.sh
启动过程中会多次要求输入密码，引出后面会讲的SSH无密登陆配置
jps查看并介绍进程
namenode
secondarynamenode
datanode
nodemanager
resourcemanager

web管理界面的使用和介绍

四、ssh免密码登陆配置
1、ssh介绍，登陆演示（需要增加一台虚拟机）
2、ssh免密码登陆的秘钥机制
3、ssh秘钥配置，权限设置
ssh-keygen.sh -t rsa
~/.ssh 目录介绍
id_ras   id_rsa.pub  known_hosts
ssh-copy-id  desthost 或scp +  cat >> 命令 
4、验证
5、ssh免密码登陆的原理，握手及身份验证流程


五、hadoop的可用性验证
1、hdfs验证
通过网页访问hdfs
hdfs  shell 命令 
hdfs dfsadmin -report查看hdfs集群状态
put  get  mv  rm的演示 

2、yarn验证
跑hadoop自带例子程序
hadoop jar app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount /input /output